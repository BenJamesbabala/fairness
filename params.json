{
  "name": "A Course on Fairness, Accuracy and Transparency in Machine Learning",
  "tagline": "Sponsored by the GIAN program of the Government of India",
  "body": "### Overview\r\n\r\nMachine learning has taken over our world, in more ways than we realize. You might get book recommendations, or an efficient route to your destination, or even a winning strategy for a game of Go. But you might also be admitted to college, granted a loan, or hired for a job based on algorithmically enhanced decision-making. We believe machines are neutral arbiters: cold, calculating entities that always make the right decision, that can see patterns that our human minds can’t or won’t. But are they? Or is decision-making-by-algorithm a way to amplify, extend and make inscrutable the biases and discrimination that is prevalent in society?\r\n\r\nTo answer these questions, we need to go back — all the way to the original ideas of justice and fairness in society. We also need to go forward — towards a mathematical framework for talking about justice and fairness in machine learning. I will talk about the growing landscape of research in algorithmic fairness: how we can reason systematically about biases in algorithms, and how we can make our algorithms fair(er).\r\n\r\n---\r\n\r\n### Syllabus\r\n---\r\n*   Dec 11: **Preliminaries**\r\n\r\n      Basics of machine learning -- supervised and unsupervised learning, empirical risk minimization, classifiers, regression, training and generalization. \r\n\r\n      *Readings*:\r\n    * Chapters 1 [(PDF)](http://ciml.info/dl/v0_9/ciml-v0_9-ch01.pdf), 3.1-3.4 [(PDF)](http://ciml.info/dl/v0_9/ciml-v0_9-ch03.pdf) and 4 [(PDF)](http://ciml.info/dl/v0_9/ciml-v0_9-ch04.pdf) of Hal Daumé's [excellent book on ML](http://ciml.info). \r\n    * Hal's [post on the ML development pipeline](http://nlpers.blogspot.com/2016/08/debugging-machine-learning.html). This is framed in terms of the way errors can creep into the modeling process, but it doubles as an excellent explanation of the pipeline itself. \r\n\r\n*   Dec 12: **Automated Decision Making**\r\n\r\n      Case studies of the use of machine learning in applications. An introduction to different formal notions of fairness.\r\n\r\n      *Readings*:\r\n    * Criminal Justice:\r\n      * Risk Assessment: ([Primer](http://www.datacivilrights.org/pubs/2015-1027/Courts_and_Predictive_Algorithms.pdf), [discussion](http://www.datacivilrights.org/pubs/2015-1027/WDN-Courts_and_Predictive_Algorithms.pdf) from Data and Civil Rights Workshop)\r\n      * Predictive Policing: ([Primer](http://www.datacivilrights.org/pubs/2015-1027/Predictive_Policing.pdf) and [discussion](http://www.datacivilrights.org/pubs/2015-1027/WDN-Predictive_Policing.pdf))\r\n      * Julia Angwin, Jeff Larson, Surya Mattu, Lauren Kirchner, [“Machine Bias\"](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)\r\n      * [Video showing predictive policing in action](http://fusion.net/story/283896/real-future-episode-12-predictive-policing/)\r\n    * Hiring:\r\n      * [On how AI can be used in hiring](http://venturebeat.com/2016/11/09/ai-is-helping-job-candidates-bypass-resume-bias-and-black-holes/) (by one company that provides solutions). [Another perspective](http://www.ca.com/us/rewrite/articles/application-economy/can-artificial-intelligence-find-the-perfect-hire.html) \r\n      * [Predicting Voice-elicited emotions](http://delivery.acm.org/10.1145/2790000/2788619/p1969-li.pdf?ip=71.195.244.110&id=2788619&acc=OA&key=4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35%2E4037F4931E565B6B&CFID=872166982&CFTOKEN=74413255&__acm__=1480927397_b769b575e3f06e480d52f70766f3a596) (from KDD 2015)\r\n    * Credit Scoring and Loans\r\n      * China's new [citizen scoring system](https://www.washingtonpost.com/world/asia_pacific/chinas-plan-to-organize-its-whole-society-around-big-data-a-rating-for-everyone/2016/10/20/1cd0dd9c-9516-11e6-ae9d-0030ac1899cd_story.html?utm_term=.f8184eeef71d)\r\n    * Education:\r\n      * [\"19 Ways Data Analysis Empowered Students and Schools\"](https://fpf.org/wp-content/uploads/2016/03/Final_19Times-Data_Mar2016-1.pdf) pages 21-26.\r\n      * [Promise and limits of learning analytics](http://www.chronicle.com.libproxy.ocean.edu:2048/article/This-Chart-Shows-the-Promise/234573)\r\n*   Dec 13: **Fairness Mechanisms I**\r\n\r\n      Understanding the different techniques for ensuring fairness in classification.\r\n*   Dec 14: **Fairness Mechanisms II**\r\n\r\n      Continued...\r\n*   Dec 15: **Belief Systems**\r\n\r\n      Axiomatic foundations of fairness and justice. Rawls and beyond.\r\n*   Dec 16: **Accountability**\r\n\r\n      Probing black-box decision-makers: estimating influence of features.\r\n*   Dec 17: **Interpretability\r\n\r\n      Building interpretable models.\r\n*   Dec 18: **Fairness, Accountability and Transparency in other areas of comuter science**\r\n\r\n      Beyond classification: unsupervised learning and representations\r\n*   Dec 19: **The Broader View**\r\n\r\n      The influence of algorithmic decision-making in the law and policy. \r\n*   Dec 20\r\n\r\n### Support or Contact\r\nEmail me at [suresh@cs.utah.edu](mailto:suresh@cs.utah.edu)",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}