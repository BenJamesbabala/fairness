---
subtitle: "Lecture 7: Fairness in Embeddings"
title: "GIAN Course on Fairness, Accuracy and Transparency in Machine Learning"
author: "Suresh Venkatasubramanian"
date: "Dec 19, 2016"
---



# IAT paper

describe implicit association test. the principle that its harder to label words with features if it goes contrary to what they expect. 

Can word embeddings reproduce the IAT: i.e words that are far are harder to associate? 

WEAT test: 

Given: target concepts X, Y, and attributes A, B. 

Null: X, Y are equally close to A, B. 

In practice, these are sets of words. and the test is average cosine similarity between X and A minus that for B, compared with same for Y. 

randomize this over all partitions of X U Y. 

Findings:

- Flowers are more pleasant than insects. 
  - Flowers, Insects = target set
  - Pleasant, unpleasant = attributes.
- musical instruments more pleasant than weapons
- Racism: european names more pleasant than african-american names. 
- European names more likely to be called for interviews. 
- females more associated with family: males with career
- females more associated with arts: males with mathematics. 

Sentiment analysis example. 

# Fairness in Rankings

Describe the underlying process that could lead to unfair rankings

Define the KL-based measure of ranking difference. 

Connect their work to the Zemel at al work. 

# Fairness as program 

# Beliefs

## Rawls

Justice as fairness

Veil of ignorance

ideas of equality of opportunity

* formal equality of opportunity
  * kind of procedural fairness. evaluation should be limited to the needs of the job
  * extension: irrelevant features should not be used. 
* substantive equality of opportunity
  * starting point may be unfair. 
  * approaches to rectify this should stop BEFORE the evaluation takes place. 

## Axioms



