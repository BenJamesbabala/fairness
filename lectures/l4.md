---
subtitle: "Lecture 4: Accountability
title: "GIAN Course on Fairness, Accuracy and Transparency in Machine Learning"
author: "Suresh Venkatasubramanian"
date: "Dec 15, 2016"
---

# Introduction

We've spent a lot of time talking about fairness preserving mechanisms and ways to measure fairness in an algorithm. But let's take a step back. If we are to determine that an algorithm is unfair, then (say in the setting of group fairness), we are saying that some protected variable (say gender) is having an undue effect on the outcome. 

But in general, is it possible to quantify what effect *any* variable is having on the outcome? This is the problem of *influence estimation*: Given a black box model represented as a function $f(x_1, \ldots, x_n)$, determine some quantity $I(x_j)$ that measures how much influence $x_j$ has on the value of $f$, in the sense that changing it might affect $f$ significantly. 

This notion is not novel. It relates to ideas about influence in Boolean functions that date back to the 80s and have had a major influence in the design of learning algorithms. It also harkens back to ideas in social choice theory like the Banzhaf index and the Shapley-Shubik power index that try to capture the power of individual voters in a voting scheme. 

But in machine learning, the idea of influence made a formal appearance in the work of Breiman, who used it to identify variables that had a strong influence on the outcome of classification by random forests. 

## Linear regression and variable coefficients

talk about linear regression and how the coefficients can indicate sensitivity. 

## Influence in random forests

Breiman's idea is a kind of permutation test, based on the following idea. 

> *if a variable is not important to the outcome of a test, then permuting its value in the data should not make a difference*

So let us suppose we have built a model from training data that takes in $n$ features $x_i$. We now take the *test* data $D$ and do the following for each variable $x_i$:

* take the column of values corresponding to $x_i$ and randomly permute them. This creates a new data set $D_i$. 
* Run the model on each $D_i$. Record the change in accuracy $\Delta_i$as the difference between the original accuracy $\Delta$ when run on the original test data, and the accuracy when run on $D_i$. 
* Then the *influence* of $x_i$ is $\Delta_i$, and the variables can be ordered in decreasing order of $\Delta_i$ to identify the ones of *decreasing* influence. 

## Correlated inputs

Breiman's approach works to identify single inputs that might influence the outcome of the model. But what happens if variable interactions appear jointly. For example, suppose you have a very simple model that takes the xor of its inputs: 

$$ f(x_1, x_2) = x_1 \oplus x_2$$

Or maybe even the more descriptive (example via Henelius et al): variable $x_i$ is influential only when variable $x_j$ takes certain values. 

The basic Breiman approach won't work here because it's only changing one variable at a time. What Henelius et al propose is something a little more involved. They consider two possible manipulations:

1. They allow for attributes to be permuted together. In effect, this is treating each group of attributes as one vector and permuting the vectors. 
2. they allow for local "in-class" permutations of attributes. In other words, they break the data set based on the class attribute and apply the permutations locally. This has the effect of doing a conditional perturbation of the data (conditioned on the class variable). 

In each case, they compare the predictions made on the new data with the predictions made on the old data, and look at the number of disagreements. They do this repeatedly and then take the average. 

The second approach is used to investigate a slightly different phenomenon: if an attibute is independent of other attributes conditioned on the class variable. Intuitively, if it is, then running the random permutation shouldn't make a difference, and so the fraction of agreements (the *fidelity*) should be high. 

The goal in their paper is to identify an "optimal" grouping of attributes with highest fideliy, which would then allow them to conclude that they've identified the interaction patterns between attributes. The rest of the paper describes an algorithm to search the space of attributes (a potentially exponentially large search space) for this optimal grouping. 

## Indirect Influence

### mention anova result

## Quantitative Influence
